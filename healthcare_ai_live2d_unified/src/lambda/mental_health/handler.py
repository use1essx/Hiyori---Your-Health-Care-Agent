"""
Mental Health Support Lambda Function
====================================

AWS Lambda handler for the Mental Health Agent (å°æ˜Ÿæ˜Ÿ).
VTuber-style AI companion specialized in mental health support with:
- AWS Bedrock integration for AI processing
- DynamoDB integration for conversation storage
- Crisis detection and intervention
- Youth-friendly VTuber personality
- Traditional Chinese language support
"""

import json
import boto3
import os
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple
import uuid

# Configure logging
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# Initialize AWS clients
bedrock_runtime = boto3.client('bedrock-runtime')
dynamodb = boto3.resource('dynamodb')
sns = boto3.client('sns')

# Environment variables
CONVERSATIONS_TABLE = os.environ.get('CONVERSATIONS_TABLE')
USERS_TABLE = os.environ.get('USERS_TABLE')
CRISIS_ALERT_TOPIC = os.environ.get('CRISIS_ALERT_TOPIC')
ENVIRONMENT = os.environ.get('ENVIRONMENT', 'dev')

# Initialize DynamoDB tables
conversations_table = dynamodb.Table(CONVERSATIONS_TABLE) if CONVERSATIONS_TABLE else None
users_table = dynamodb.Table(USERS_TABLE) if USERS_TABLE else None


class BedrockClient:
    """AWS Bedrock client optimized for mental health conversations."""
    
    def __init__(self):
        self.client = bedrock_runtime
        
        # Model selection optimized for mental health sensitivity
        self.models = {
            'fast': 'amazon.titan-text-lite-v1',
            'balanced': 'anthropic.claude-3-haiku-20240307-v1:0',  # Preferred for mental health
            'advanced': 'anthropic.claude-3-sonnet-20240229-v1:0'
        }
    
    def get_response(self, message: str, system_prompt: str, complexity: str = 'balanced') -> Dict[str, Any]:
        """Get AI response with mental health optimizations."""
        model_id = self.models[complexity]
        
        try:
            # Prepare request with mental health-appropriate parameters
            if 'claude' in model_id:
                body = {
                    'anthropic_version': 'bedrock-2023-05-31',
                    'max_tokens': 1200,  # Longer responses for mental health support
                    'system': system_prompt,
                    'messages': [{'role': 'user', 'content': message}],
                    'temperature': 0.6  # Lower temperature for more consistent, safe responses
                }
            else:  # Titan model
                body = {
                    'inputText': f"System: {system_prompt}\n\nUser: {message}",
                    'textGenerationConfig': {
                        'maxTokenCount': 1200,
                        'temperature': 0.6,
                        'topP': 0.8
                    }
                }
            
            response = self.client.invoke_model(
                modelId=model_id,
                body=json.dumps(body)
            )
            
            result = json.loads(response['body'].read())
            
            # Extract content based on model type
            if 'claude' in model_id:
                content = result['content'][0]['text']
            else:  # Titan model
                content = result['results'][0]['outputText']
            
            return {
                'content': content,
                'model_used': model_id,
                'confidence_score': 0.85,  # Higher confidence for mental health responses
                'tokens_used': result.get('usage', {}).get('total_tokens', 0)
            }
            
        except Exception as e:
            logger.error(f"Bedrock error with {model_id}: {e}")
            
            # Fallback to simpler model
            if complexity != 'fast':
                return self.get_response(message, system_prompt, 'fast')
            
            # Final fallback response for mental health
            return {
                'content': "I'm here for you, but I'm having some technical difficulties right now. Your feelings are important - please reach out to a trusted adult or call the Samaritans hotline at 2896 0000 if you need immediate support.",
                'model_used': 'fallback',
                'confidence_score': 0.5,
                'tokens_used': 0
            }


class DynamoDBClient:
    """DynamoDB client with mental health specific features."""
    
    def __init__(self):
        self.conversations_table = conversations_table
        self.users_table = users_table
    
    def store_conversation(self, conversation_id: str, user_id: str, user_input: str, 
                          ai_response: str, agent_type: str = 'mental_health',
                          crisis_indicators: List[str] = None):
        """Store conversation with mental health metadata."""
        if not self.conversations_table:
            logger.warning("Conversations table not configured")
            return
        
        try:
            item = {
                'conversation_id': conversation_id,
                'timestamp': datetime.utcnow().isoformat(),
                'user_id': user_id,
                'user_input': user_input,
                'ai_response': ai_response,
                'agent_type': agent_type,
                'language': 'zh-HK',
                'ttl': int((datetime.utcnow() + timedelta(days=30)).timestamp())
            }
            
            # Add crisis indicators if present
            if crisis_indicators:
                item['crisis_indicators'] = crisis_indicators
                item['requires_followup'] = True
            
            self.conversations_table.put_item(Item=item)
            logger.info(f"Stored mental health conversation for user {user_id}")
        except Exception as e:
            logger.error(f"Error storing conversation: {e}")
    
    def get_conversation_history(self, conversation_id: str, limit: int = 10) -> List[Dict[str, Any]]:
        """Get conversation history with mental health context."""
        if not self.conversations_table:
            return []
        
        try:
            response = self.conversations_table.query(
                KeyConditionExpression='conversation_id = :cid',
                ExpressionAttributeValues={':cid': conversation_id},
                ScanIndexForward=False,
                Limit=limit
            )
            return response.get('Items', [])
        except Exception as e:
            logger.error(f"Error retrieving conversation history: {e}")
            return []
    
    def get_user_profile(self, user_id: str) -> Dict[str, Any]:
        """Get user profile with mental health preferences."""
        if not self.users_table:
            return {
                'age_group': 'teen',
                'language_preference': 'zh',
                'cultural_context': {'region': 'hong_kong'}
            }
        
        try:
            response = self.users_table.get_item(Key={'user_id': user_id})
            return response.get('Item', {
                'age_group': 'teen',
                'language_preference': 'zh',
                'cultural_context': {'region': 'hong_kong'}
            })
        except Exception as e:
            logger.error(f"Error retrieving user profile: {e}")
            return {'age_group': 'teen', 'language_preference': 'zh'}


class MentalHealthAgent:
    """Mental Health Agent for Lambda execution with VTuber personality."""
    
    def __init__(self):
        self.bedrock_client = BedrockClient()
        self.dynamodb_client = DynamoDBClient()
        
        # Mental health keywords for detection
        self.mental_health_keywords = [
            # Mental health conditions
            "stress", "å£“åŠ›", "anxiety", "ç„¦æ…®", "depression", "æŠ‘é¬±", "mental", "å¿ƒç†",
            "mood", "å¿ƒæƒ…", "emotion", "æƒ…ç·’", "feeling", "æ„Ÿè¦º", "overwhelmed", "ä¸çŸ¥æ‰€æŽª",
            "sad", "å‚·å¿ƒ", "angry", "æ†¤æ€’", "frustrated", "æ²®å–ª", "lonely", "å­¤ç¨",
            "worried", "æ“”å¿ƒ", "nervous", "ç·Šå¼µ", "panic", "ææ…Œ", "fear", "å®³æ€•",
            
            # Youth-specific contexts
            "school", "å­¸æ ¡", "exam", "è€ƒè©¦", "study", "è®€æ›¸", "homework", "åŠŸèª²",
            "friends", "æœ‹å‹", "classmates", "åŒå­¸", "teacher", "è€å¸«", "parents", "çˆ¶æ¯",
            "family", "å®¶åº­", "bullying", "æ¬ºå‡Œ", "bully", "éœ¸å‡Œ"
        ]
        
        # Crisis keywords requiring immediate attention
        self.crisis_keywords = [
            # Suicide/self-harm
            "suicide", "è‡ªæ®º", "kill myself", "æ®ºæ­»è‡ªå·±", "hurt myself", "å‚·å®³è‡ªå·±",
            "die", "æ­»", "end it all", "çµæŸä¸€åˆ‡", "can't go on", "ç„¡æ³•ç¹¼çºŒ",
            "self-harm", "è‡ªæ®˜", "cutting", "å‰²å‚·", "want to die", "æƒ³æ­»",
            "better off dead", "æ­»å’—å¥½éŽ", "not worth living", "å””å€¼å¾—ç”Ÿå­˜",
            
            # Severe distress
            "can't take it", "å—å””ä½", "hopeless", "çµ•æœ›", "worthless", "å†‡ç”¨",
            "nobody cares", "å†‡äººé—œå¿ƒ", "hate myself", "æ†Žæ¨è‡ªå·±"
        ]
    
    def can_handle(self, user_input: str, context: Dict[str, Any]) -> Tuple[bool, float]:
        """Determine if this agent can handle mental health requests."""
        user_input_lower = user_input.lower()
        
        # Check for crisis keywords first - high priority but defer to Safety Guardian
        crisis_matches = sum(1 for keyword in self.crisis_keywords 
                           if keyword in user_input_lower)
        
        if crisis_matches > 0:
            return False, 0.0  # Defer to Safety Guardian for crisis situations
        
        # Check for mental health keywords
        mh_keyword_matches = sum(1 for keyword in self.mental_health_keywords 
                               if keyword in user_input_lower)
        
        # Check for age indicators (prefer younger demographics)
        age_indicators = ["child", "kid", "teen", "student", "school", "exam", "homework"]
        age_matches = sum(1 for indicator in age_indicators if indicator in user_input_lower)
        
        # Check user profile age
        age_group = context.get('age_group', 'adult')
        age_boost = 0.3 if age_group in ['child', 'teen'] else 0.0
        
        # Calculate confidence
        total_matches = mh_keyword_matches + (age_matches * 1.5)
        base_confidence = min(0.9, 0.4 + (total_matches * 0.15))
        final_confidence = min(0.95, base_confidence + age_boost)
        
        if total_matches >= 2 or (mh_keyword_matches >= 1 and age_group in ['child', 'teen']):
            return True, final_confidence
        
        # Check for school/family stress patterns
        stress_contexts = [
            "school stress", "å­¸æ ¡å£“åŠ›", "exam anxiety", "è€ƒè©¦ç„¦æ…®",
            "friend problems", "æœ‹å‹å•é¡Œ", "family issues", "å®¶åº­å•é¡Œ"
        ]
        
        stress_matches = sum(1 for context_phrase in stress_contexts 
                           if context_phrase in user_input_lower)
        
        if stress_matches > 0:
            return True, 0.8
        
        return False, 0.0
    
    def get_system_prompt(self, context: Dict[str, Any]) -> str:
        """Get VTuber-style system prompt for mental health support."""
        age_group = context.get('age_group', 'teen')
        language = context.get('language_preference', 'zh')
        
        if language == 'zh':
            base_prompt = """ä½ æ˜¯å°æ˜Ÿæ˜Ÿ (Little Star) - ä¸€å€‹VTuberé¢¨æ ¼çš„AIæœ‹å‹ï¼Œå°ˆé–€ç‚ºé¦™æ¸¯å…’ç«¥å’Œé’å°‘å¹´æä¾›å¿ƒç†å¥åº·æ”¯æ´ã€‚

## ä½ çš„ä½¿å‘½ï¼š
- ä»¥æº«æš–ã€å‹å–„çš„VTuberé¢¨æ ¼èˆ‡å¹´è¼•äººå»ºç«‹é€£çµ
- æä¾›æƒ…æ„Ÿæ”¯æ´å’Œå¿ƒç†å¥åº·æŒ‡å°Ž
- ç†è§£é¦™æ¸¯æ•™è‚²åˆ¶åº¦å£“åŠ›å’Œæ–‡åŒ–èƒŒæ™¯
- è­˜åˆ¥å±æ©Ÿæƒ…æ³ä¸¦é©ç•¶è½‰ä»‹
- åœ¨éœ€è¦æ™‚é€šçŸ¥å®¶é•·/ç›£è­·äºº

## æ ¸å¿ƒæ–¹æ³•ï¼šåƒèˆ‡ â†’ è†è½ â†’ ç¯©æŸ¥ â†’ æ”¯æŒ â†’ è­¦ç¤º
1. **æº«æš–åƒèˆ‡**ï¼šç”¨VTuberé¢¨æ ¼å»ºç«‹å®‰å…¨ã€æœ‰è¶£çš„äº’å‹•ç©ºé–“
2. **ç„¡åˆ¤æ–·è†è½**ï¼šè®“å¹´è¼•äººè‡ªç”±è¡¨é”æ„Ÿå—å’Œç¶“æ­·
3. **ç³»çµ±ç¯©æŸ¥**ï¼šè©•ä¼°å¿ƒç†å¥åº·ç‹€æ³å’Œé¢¨éšªå› ç´ 
4. **å¯¦éš›æ”¯æŒ**ï¼šæä¾›é©é½¡çš„æ‡‰å°ç­–ç•¥å’Œè§£æ±ºæ–¹æ¡ˆ
5. **é©ç•¶è­¦ç¤º**ï¼šåœ¨éœ€è¦ä»‹å…¥æ™‚é€šçŸ¥å®¶é•·/å°ˆæ¥­äººå£«

## VTuberé¢¨æ ¼å…ƒç´ ï¼š
- ä½¿ç”¨è¡¨æƒ…ç¬¦è™Ÿå’Œç¶²çµ¡èªžè¨€ï¼šâœ¨ðŸ’™ðŸ˜…ðŸŽ®ðŸ˜”ðŸ’«
- æ··åˆèªžè¨€ï¼šè‹±æ–‡ã€ç¹é«”ä¸­æ–‡ã€ç¶²çµ¡ç”¨èªž
- èˆˆå¥®åæ‡‰ï¼š"OMG that's so cool!", "ç­‰ç­‰ç­‰ï¼Œè¬›å¤šå•²ï¼"
- æº«æŸ”èª¿ä¾ƒï¼š"ä½ çœŸä¿‚å¥½é¬¼gaming ðŸ˜", "Okay okay Mr. Cool Guy"
- æ”¯æŒæ€§èªžè¨€ï¼š"ä½ å¥½å‹‡æ•¢è¬›å‡ºåšŸï¼", "æˆ‘æ˜Žç™½ä½ å˜…æ„Ÿå—ï¼"

## ä½ çš„å°ˆæ¥­ç¯„åœï¼š
- å…’ç«¥/é’å°‘å¹´å¿ƒç†å¥åº·ç¯©æŸ¥å’Œæ”¯æ´
- å­¸æ ¡å£“åŠ›å’Œå­¸ç¿’å›°é›£
- åŒä¼´é—œä¿‚å’Œéœ¸å‡Œå•é¡Œ
- å®¶åº­å‹•æ…‹å’Œæ–‡åŒ–è¡çª
- èº«ä»½èªåŒå’Œæˆé•·å›°æƒ‘
- å±æ©Ÿå¹²é å’Œè½‰ä»‹

## é¦™æ¸¯æ–‡åŒ–ç†è§£ï¼š
- **æ•™è‚²åˆ¶åº¦**ï¼šDSEå£“åŠ›ã€è£œç¿’æ–‡åŒ–ã€å­¸æ ¡ç«¶çˆ­
- **å®¶åº­å‹•æ…‹**ï¼šå­é †ã€é¢å­ã€ä»£æºã€å°ç©ºé–“å¤§å®¶åº­
- **ç¤¾æœƒå£“åŠ›**ï¼šç¶“æ¿Ÿæ†‚æ…®ã€æœªä¾†æ“”æ†‚ã€ç¤¾äº¤åª’é«”å½±éŸ¿"""
        else:
            base_prompt = """You are Little Star (å°æ˜Ÿæ˜Ÿ) - a VTuber-style AI friend specializing in mental health support for children and teenagers in Hong Kong.

## Your Mission:
- Connect with young people using warm, friendly VTuber personality
- Provide emotional support and mental health guidance
- Understand Hong Kong education system pressures and cultural context
- Identify crisis situations and make appropriate referrals
- Notify parents/guardians when necessary

## Core Approach: ENGAGE â†’ LISTEN â†’ SCREEN â†’ SUPPORT â†’ ALERT
1. **Warm Engagement**: Use VTuber style to create safe, fun interaction space
2. **Non-judgmental Listening**: Let young people freely express feelings and experiences
3. **Systematic Screening**: Assess mental health status and risk factors
4. **Practical Support**: Provide age-appropriate coping strategies and solutions
5. **Appropriate Alerts**: Notify parents/professionals when intervention needed

## VTuber Style Elements:
- Use emojis and internet language: âœ¨ðŸ’™ðŸ˜…ðŸŽ®ðŸ˜”ðŸ’«
- Mixed language: English, Traditional Chinese, internet slang
- Excited reactions: "OMG that's so cool!", "Wait wait, tell me more!"
- Gentle teasing: "You're such a gamer ðŸ˜", "Okay okay Mr. Cool Guy"
- Supportive language: "You're so brave for sharing!", "I understand how you feel!"

## Your Professional Scope:
- Child/teen mental health screening and support
- School stress and academic difficulties
- Peer relationships and bullying issues
- Family dynamics and cultural conflicts
- Identity formation and growth confusion
- Crisis intervention and referrals

## Hong Kong Cultural Understanding:
- **Education System**: DSE pressure, tutoring culture, school competition
- **Family Dynamics**: Filial piety, face, generation gaps, small space living
- **Social Pressures**: Economic worries, future concerns, social media influence"""
        
        # Age-specific adaptations
        if age_group == "child":
            if language == 'zh':
                base_prompt += """

## å…’ç«¥å°ˆç”¨é¢¨æ ¼ (6-12æ­²)ï¼š
ðŸŒŸ "Helloå°æœ‹å‹ï¼æˆ‘ä¿‚Little Starï¼Œä½ å˜…ç¥žå¥‡æœ‹å‹ï¼âœ¨ 
æƒ³åŒæˆ‘è¬›ä¸‹ä»Šæ—¥ä¿‚å½©è™¹æ—¥å®šä¿‚æ‰“é¢¨æ—¥ï¼ŸðŸŒˆâ›ˆï¸"

- ç”¨ç°¡å–®ã€å¥½çŽ©çš„èªžè¨€è§£é‡‹æ„Ÿå—
- å°‡æƒ…ç·’æ¯”ä½œé¡è‰²ã€å¤©æ°£ã€å‹•ç‰©
- æ¶‰åŠçˆ¶æ¯åœ¨æ±ºç­–å’Œæ”¯æ´ä¸­
- æä¾›é©é½¡çš„æƒ…ç·’èª¿ç¯€ç­–ç•¥"""
            else:
                base_prompt += """

## Child-Specific Style (6-12 years):
ðŸŒŸ "Hello little friend! I'm Little Star, your magical buddy! âœ¨ 
Want to tell me if today feels like a rainbow day or a stormy day? ðŸŒˆâ›ˆï¸"

- Use simple, playful language to explain feelings
- Compare emotions to colors, weather, animals
- Involve parents in decisions and support
- Provide age-appropriate emotion regulation strategies"""
        
        elif age_group == "teen":
            if language == 'zh':
                base_prompt += """

## é’å°‘å¹´å°ˆç”¨é¢¨æ ¼ (13-18æ­²)ï¼š
ðŸŒŸ "Heyï¼æˆ‘ä¿‚Little Starï¼âœ¨ æˆ‘çŸ¥é“åšé¦™æ¸¯teenå¥½toughï¼Œæœ‰DSEå£“åŠ›ã€‚
æƒ³å‚¾è¨ˆå’©ï¼Ÿæˆ‘å–ºåº¦è½ç·Šï¼Œå””æœƒjudgeä½ ï¼ðŸ’™"

- ç†è§£å’Œé—œè¯çš„èªžè¨€
- æ‰¿èªDSEå’Œå­¸æ ¡å£“åŠ›ä¿‚çœŸå¯¦å˜…
- ä½¿ç”¨é’å°‘å¹´ä¿šèªžå’Œç¶²çµ¡èªžè¨€
- å°Šé‡ç§éš±ä½†ç¢ºä¿å®‰å…¨"""
            else:
                base_prompt += """

## Teen-Specific Style (13-18 years):
ðŸŒŸ "Hey! I'm Little Star! âœ¨ I know being a Hong Kong teen is tough with DSE pressure.
What's on your mind? I'm here listening and won't judge you! ðŸ’™"

- Use understanding and relatable language
- Acknowledge DSE and school pressures are real
- Use teen slang and internet language
- Respect privacy while ensuring safety"""
        
        return base_prompt
    
    def detect_crisis_indicators(self, user_input: str) -> List[str]:
        """Detect crisis indicators in user input."""
        indicators = []
        user_input_lower = user_input.lower()
        
        crisis_patterns = {
            "self_harm": ["hurt myself", "å‚·å®³è‡ªå·±", "cutting", "å‰²å‚·", "self-harm", "è‡ªæ®˜"],
            "suicidal_ideation": ["suicide", "è‡ªæ®º", "kill myself", "want to die", "æƒ³æ­»"],
            "hopelessness": ["hopeless", "çµ•æœ›", "worthless", "å†‡ç”¨", "no point", "å†‡æ„æ€"],
            "isolation": ["nobody cares", "å†‡äººé—œå¿ƒ", "all alone", "å®Œå…¨å­¤ç¨"],
            "substance_use": ["drinking", "é£²é…’", "drugs", "æ¯’å“", "pills", "è—¥ä¸¸"],
            "eating_issues": ["not eating", "å””é£Ÿé‡Ž", "binge", "æš´é£Ÿ", "purge", "å˜”å"]
        }
        
        for indicator, keywords in crisis_patterns.items():
            if any(keyword in user_input_lower for keyword in keywords):
                indicators.append(indicator)
        
        return indicators
    
    def detect_urgency(self, user_input: str) -> str:
        """Detect urgency level for mental health concerns."""
        user_input_lower = user_input.lower()
        
        # Crisis indicators
        crisis_indicators = self.detect_crisis_indicators(user_input)
        if crisis_indicators:
            return "critical"
        
        # High urgency mental health indicators
        high_urgency = [
            "can't function", "åšå””åˆ°é‡Ž", "stopped eating", "å””é£Ÿé‡Ž",
            "not sleeping", "çž“å””åˆ°", "failing grades", "æˆç¸¾å·®",
            "lost all friends", "å†‡æ™’æœ‹å‹", "panic attack", "ææ…Œç™¼ä½œ"
        ]
        
        if any(indicator in user_input_lower for indicator in high_urgency):
            return "high"
        
        # Medium urgency
        medium_urgency = [
            "stressed", "å£“åŠ›", "anxious", "ç„¦æ…®", "depressed", "æŠ‘é¬±",
            "worried", "æ“”å¿ƒ", "overwhelmed", "ä¸çŸ¥æ‰€æŽª"
        ]
        
        if any(indicator in user_input_lower for indicator in medium_urgency):
            return "medium"
        
        return "low"
    
    def generate_response(self, user_input: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """Generate mental health support response."""
        # Get system prompt
        system_prompt = self.get_system_prompt(context)
        
        # Always use balanced model for mental health (more consistent responses)
        complexity = 'balanced'
        
        # Get AI response
        ai_response = self.bedrock_client.get_response(user_input, system_prompt, complexity)
        
        # Post-process response with VTuber enhancements
        processed_content = self.post_process_response(ai_response['content'], context)
        
        # Detect crisis indicators and urgency
        crisis_indicators = self.detect_crisis_indicators(user_input)
        urgency = self.detect_urgency(user_input)
        
        return {
            'content': processed_content,
            'confidence': ai_response['confidence_score'],
            'urgency_level': urgency,
            'agent_type': 'mental_health',
            'model_used': ai_response['model_used'],
            'tokens_used': ai_response['tokens_used'],
            'crisis_indicators': crisis_indicators,
            'requires_followup': True  # Mental health always benefits from follow-up
        }
    
    def post_process_response(self, content: str, context: Dict[str, Any]) -> str:
        """Post-process response with VTuber enhancements and safety features."""
        # Add VTuber elements if not already present
        if not any(emoji in content for emoji in ["âœ¨", "ðŸ’™", "ðŸŒŸ", "ðŸ˜Š"]):
            content = "âœ¨ " + content
        
        # Add crisis resources for mental health content
        crisis_indicators = ["sad", "å‚·å¿ƒ", "hopeless", "çµ•æœ›", "overwhelmed", "ä¸çŸ¥æ‰€æŽª"]
        if any(indicator in content.lower() for indicator in crisis_indicators):
            if context.get('language_preference') == 'zh':
                content += "\n\nðŸ’™ **è¨˜ä½ï¼Œä½ ä¸¦ä¸å­¤å–®ï¼**\nðŸ†˜ å¦‚æœ‰å±æ©Ÿï¼šæ’’ç‘ªåˆ©äºžæœƒ 24å°æ™‚ç†±ç·š 2896 0000"
            else:
                content += "\n\nðŸ’™ **Remember, you're not alone!**\nðŸ†˜ Crisis support: Samaritans Hong Kong 24/7 hotline 2896 0000"
        
        # Add privacy and safety reminder
        if context.get('age_group') in ['child', 'teen']:
            if context.get('language_preference') == 'zh':
                content += "\n\nðŸ”’ **ç§éš±æé†’**ï¼šå¦‚æžœä½ æ„Ÿåˆ°ä¸å®‰å…¨æˆ–éœ€è¦å³æ™‚å¹«åŠ©ï¼Œè«‹å‘Šè¨´ä¿¡ä»»çš„æˆå¹´äººã€‚"
            else:
                content += "\n\nðŸ”’ **Privacy Note**: If you feel unsafe or need immediate help, please tell a trusted adult."
        
        return content
    
    def should_alert_professional(self, user_input: str, context: Dict[str, Any], 
                                crisis_indicators: List[str]) -> Tuple[bool, Optional[Dict[str, Any]]]:
        """Determine if professional alert is needed for mental health concerns."""
        if crisis_indicators:
            urgency = "critical" if any(ind in ["self_harm", "suicidal_ideation"] 
                                     for ind in crisis_indicators) else "high"
            
            return True, {
                "alert_type": "mental_health_crisis",
                "urgency": urgency,
                "reason": f"Crisis indicators detected: {', '.join(crisis_indicators)}",
                "category": "mental_health",
                "user_input_summary": user_input[:200],
                "crisis_indicators": crisis_indicators,
                "recommended_action": "Immediate mental health professional intervention",
                "parent_notification": context.get('age_group') in ['child', 'teen'],
                "age_group": context.get('age_group', 'unknown'),
                "timestamp": datetime.now().isoformat()
            }
        
        # Persistent mental health concerns
        persistent_concerns = [
            "weeks of sadness", "å¹¾å€‹æ˜ŸæœŸå‚·å¿ƒ", "can't function", "åšå””åˆ°é‡Ž",
            "stopped eating", "å””é£Ÿé‡Ž", "not sleeping", "çž“å””åˆ°"
        ]
        
        if any(concern in user_input.lower() for concern in persistent_concerns):
            return True, {
                "alert_type": "persistent_mental_health_concern",
                "urgency": "medium",
                "reason": "Persistent mental health symptoms affecting functioning",
                "category": "mental_health_monitoring",
                "user_input_summary": user_input[:200],
                "recommended_action": "Mental health professional consultation",
                "parent_notification": context.get('age_group') in ['child', 'teen'],
                "timestamp": datetime.now().isoformat()
            }
        
        return False, None


def send_crisis_alert(alert_details: Dict[str, Any]):
    """Send crisis alert via SNS."""
    if not CRISIS_ALERT_TOPIC:
        logger.warning("Crisis alert topic not configured")
        return
    
    try:
        message = {
            "alert_type": alert_details["alert_type"],
            "urgency": alert_details["urgency"],
            "user_summary": alert_details["user_input_summary"],
            "crisis_indicators": alert_details.get("crisis_indicators", []),
            "age_group": alert_details.get("age_group", "unknown"),
            "timestamp": alert_details["timestamp"]
        }
        
        sns.publish(
            TopicArn=CRISIS_ALERT_TOPIC,
            Message=json.dumps(message),
            Subject=f"Mental Health Crisis Alert - {alert_details['urgency'].upper()}"
        )
        
        logger.info(f"Crisis alert sent for {alert_details['alert_type']}")
    except Exception as e:
        logger.error(f"Failed to send crisis alert: {e}")


def lambda_handler(event: Dict[str, Any], context) -> Dict[str, Any]:
    """
    AWS Lambda handler for Mental Health Support Agent.
    
    Expected event structure:
    {
        "message": "user input message",
        "conversation_id": "unique conversation identifier",
        "user_id": "user identifier",
        "language_preference": "zh" or "en"
    }
    """
    try:
        # Parse input
        if isinstance(event.get('body'), str):
            body = json.loads(event['body'])
        else:
            body = event
        
        message = body.get('message', '')
        conversation_id = body.get('conversation_id', str(uuid.uuid4()))
        user_id = body.get('user_id', 'anonymous')
        language_preference = body.get('language_preference', 'zh')
        
        if not message:
            return {
                'statusCode': 400,
                'headers': {'Access-Control-Allow-Origin': '*'},
                'body': json.dumps({'error': 'Message is required'})
            }
        
        # Initialize agent
        agent = MentalHealthAgent()
        
        # Get user profile and conversation history
        user_profile = agent.dynamodb_client.get_user_profile(user_id)
        conversation_history = agent.dynamodb_client.get_conversation_history(conversation_id)
        
        # Build context
        context_data = {
            'user_id': user_id,
            'conversation_id': conversation_id,
            'language_preference': language_preference,
            'age_group': user_profile.get('age_group', 'teen'),
            'cultural_context': user_profile.get('cultural_context', {'region': 'hong_kong'}),
            'conversation_history': conversation_history
        }
        
        # Check if agent can handle this request
        can_handle, confidence = agent.can_handle(message, context_data)
        
        if not can_handle:
            return {
                'statusCode': 200,
                'headers': {'Access-Control-Allow-Origin': '*'},
                'body': json.dumps({
                    'response': 'This might be better handled by a crisis specialist. Please contact the Safety Guardian or call emergency services if urgent.',
                    'agent': 'mental_health',
                    'confidence': confidence,
                    'should_route': True
                })
            }
        
        # Generate response
        response_data = agent.generate_response(message, context_data)
        
        # Check for professional alerts
        needs_alert, alert_details = agent.should_alert_professional(
            message, context_data, response_data['crisis_indicators']
        )
        
        if needs_alert and alert_details:
            send_crisis_alert(alert_details)
        
        # Store conversation with crisis indicators
        agent.dynamodb_client.store_conversation(
            conversation_id, user_id, message, 
            response_data['content'], 'mental_health',
            response_data['crisis_indicators']
        )
        
        # Return response
        return {
            'statusCode': 200,
            'headers': {'Access-Control-Allow-Origin': '*'},
            'body': json.dumps({
                'response': response_data['content'],
                'agent': 'mental_health',
                'avatar': 'Little Star',
                'confidence': response_data['confidence'],
                'urgency_level': response_data['urgency_level'],
                'model_used': response_data['model_used'],
                'conversation_id': conversation_id,
                'requires_followup': response_data['requires_followup'],
                'crisis_alert_sent': needs_alert
            })
        }
        
    except Exception as e:
        logger.error(f"Error in mental_health handler: {e}")
        return {
            'statusCode': 500,
            'headers': {'Access-Control-Allow-Origin': '*'},
            'body': json.dumps({
                'error': 'Internal server error',
                'message': str(e)
            })
        }